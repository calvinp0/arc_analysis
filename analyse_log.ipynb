{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to identify conformer runs\n",
    "conformer_run_pattern = re.compile(\n",
    "    r\"Running local queue job conformer(\\d+) \\((a\\d+)\\) using gaussian for (TS\\d+)\"\n",
    ")\n",
    "\n",
    "# Pattern to identify failed jobs\n",
    "failed_job_pattern = re.compile(\n",
    "    r\"Warning: Troubleshooting (TS\\d+) job (conformer\\d+|opt_\\w+) which failed with status: \\\"errored,\\\"\"\n",
    ")\n",
    "\n",
    "# Pattern to identify methods attempted in failure\n",
    "methods_attempted_pattern = re.compile(\n",
    "    r\"Error: Could not troubleshoot geometry optimization for (TS\\d+)! Tried troubleshooting with the following methods: \\[(.*?)\\]\"\n",
    ")\n",
    "\n",
    "# Pattern to identify successful conformers\n",
    "successful_conformer_pattern = re.compile(\n",
    "    r\"TS guess\\s+(\\d+) for (TS\\d+)\\.\"\n",
    ")\n",
    "\n",
    "# Pattern to identify optimization runs\n",
    "optimization_run_pattern = re.compile(\n",
    "    r\"Running local queue job (opt_\\w+) using gaussian for (TS\\d+) \\(conformer (\\d+)\\)\"\n",
    ")\n",
    "\n",
    "# Pattern to identify optimization failures with methods\n",
    "optimization_failure_methods_pattern = re.compile(\n",
    "    r\"Troubleshooting opt job in gaussian for (TS\\d+) using (.*)\"\n",
    ")\n",
    "\n",
    "# Pattern to identify status dictionary after failed optimization\n",
    "status_dict_pattern = re.compile(\n",
    "    r\"TS (TS\\d+) did not converge\\. Status is:\\s+(\\{.*\\})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure to store conformer information\n",
    "ts_conformers = defaultdict(lambda: {\"conformers\": [], \"failed_conformers\": {}})\n",
    "\n",
    "# Data structure to store optimization information\n",
    "ts_optimizations = defaultdict(lambda: defaultdict(lambda: {\"jobs\": [], \"status\": None}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_arc_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparse_arc_log\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_746/arc.log\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_arc_log' is not defined"
     ]
    }
   ],
   "source": [
    "parse_arc_log(\"/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_746/arc.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_conformers_to_csv(ts_conformers, csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['TS', 'Conformer', 'Status', 'Methods']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for ts, data in ts_conformers.items():\n",
    "            # Write successful conformers\n",
    "            for conformer in data[\"conformers\"]:\n",
    "                writer.writerow({\n",
    "                    'TS': ts,\n",
    "                    'Conformer': f\"Conformer {conformer['conformer']}\",\n",
    "                    'Status': conformer['status'],\n",
    "                    'Methods': \"\"\n",
    "                })\n",
    "            # Write failed conformers\n",
    "            for conformer, details in data[\"failed_conformers\"].items():\n",
    "                writer.writerow({\n",
    "                    'TS': ts,\n",
    "                    'Conformer': f\"Conformer {conformer}\",\n",
    "                    'Status': details['status'],\n",
    "                    'Methods': details['methods']\n",
    "                })\n",
    "\n",
    "def write_optimizations_to_csv(ts_optimizations, csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['TS', 'Optimization', 'Jobs', 'Status']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for ts, optimizations in ts_optimizations.items():\n",
    "            for opt_num, details in optimizations.items():\n",
    "                writer.writerow({\n",
    "                    'TS': ts,\n",
    "                    'Optimization': f\"Optimization {opt_num}\",\n",
    "                    'Jobs': details['jobs'],\n",
    "                    'Status': details.get('status', \"\")\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_746/arc.log\"\n",
    "conformers_csv = 'conformers.csv'\n",
    "optimizations_csv = 'optimizations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_arc_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ts_conformers, ts_optimizations \u001b[38;5;241m=\u001b[39m \u001b[43mparse_arc_log\u001b[49m(log_file_path)\n\u001b[1;32m      3\u001b[0m write_conformers_to_csv(ts_conformers, conformers_csv)\n\u001b[1;32m      4\u001b[0m write_optimizations_to_csv(ts_optimizations, optimizations_csv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parse_arc_log' is not defined"
     ]
    }
   ],
   "source": [
    "    ts_conformers, ts_optimizations = parse_arc_log(log_file_path)\n",
    "    \n",
    "    write_conformers_to_csv(ts_conformers, conformers_csv)\n",
    "    write_optimizations_to_csv(ts_optimizations, optimizations_csv)\n",
    "\n",
    "    print(f\"Conformers data written to {conformers_csv}\")\n",
    "    print(f\"Optimizations data written to {optimizations_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conformers data written to conformers.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define regex patterns\n",
    "conformer_run_pattern = re.compile(\n",
    "    r\"Running local queue job conformer(\\d+) \\((a\\d+)\\) using gaussian for (TS\\d+)\"\n",
    ")\n",
    "\n",
    "failed_job_pattern = re.compile(\n",
    "    r\"Warning: Troubleshooting (TS\\d+) job (conformer\\d+|opt_\\w+) which failed with status: \\\"errored,\\\"\"\n",
    ")\n",
    "\n",
    "methods_attempted_pattern = re.compile(\n",
    "    r\"Error: Could not troubleshoot geometry optimization for (TS\\d+)! Tried troubleshooting with the following methods: \\[(.*?)\\]\"\n",
    ")\n",
    "\n",
    "successful_conformer_pattern = re.compile(\n",
    "    r\"TS guess\\s+(\\d+) for (TS\\d+)\\.\"\n",
    ")\n",
    "\n",
    "# Initialize data structures\n",
    "ts_conformers = defaultdict(dict)  # {TS: {conformer_num: {status: ..., methods: ...}}}\n",
    "\n",
    "def parse_arc_log(log_file_path):\n",
    "    with open(log_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "\n",
    "        # Check for conformer runs\n",
    "        conformer_run_match = conformer_run_pattern.match(line)\n",
    "        if conformer_run_match:\n",
    "            conformer_num, job_id, ts = conformer_run_match.groups()\n",
    "            conformer_num = int(conformer_num)\n",
    "            ts_conformers[ts][conformer_num] = {\n",
    "                \"Conformer\": f\"Conformer {conformer_num}\",\n",
    "                \"Status\": \"RUNNING\",\n",
    "                \"Methods\": \"\"\n",
    "            }\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Check for failed jobs\n",
    "        failed_job_match = failed_job_pattern.match(line)\n",
    "        if failed_job_match:\n",
    "            ts, job = failed_job_match.groups()\n",
    "            if job.startswith(\"conformer\"):\n",
    "                conformer_num = int(re.findall(r'\\d+', job)[0])\n",
    "                if ts in ts_conformers and conformer_num in ts_conformers[ts]:\n",
    "                    ts_conformers[ts][conformer_num][\"Status\"] = \"FAILED\"\n",
    "                else:\n",
    "                    # If the conformer wasn't previously RUNNING, initialize it\n",
    "                    ts_conformers[ts][conformer_num] = {\n",
    "                        \"Conformer\": f\"Conformer {conformer_num}\",\n",
    "                        \"Status\": \"FAILED\",\n",
    "                        \"Methods\": \"\"\n",
    "                    }\n",
    "                # Extract methods from subsequent lines\n",
    "                # Assuming methods are listed in the line that contains \"Tried troubleshooting...\"\n",
    "                methods_line = lines[i + 4].strip() if i + 4 < len(lines) else \"\"\n",
    "                methods_match = re.findall(r\"'([^']+)'\", methods_line)\n",
    "                if methods_match:\n",
    "                    ts_conformers[ts][conformer_num][\"Methods\"] = methods_match\n",
    "            elif job.startswith(\"opt_\"):\n",
    "                # Handle optimization jobs if needed\n",
    "                pass  # For this example, we're focusing on conformers\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Check for successful conformers\n",
    "        successful_conformer_match = successful_conformer_pattern.match(line)\n",
    "        if successful_conformer_match:\n",
    "            conformer_num, ts = successful_conformer_match.groups()\n",
    "            conformer_num = int(conformer_num)\n",
    "            if ts in ts_conformers and conformer_num in ts_conformers[ts]:\n",
    "                ts_conformers[ts][conformer_num][\"Status\"] = \"SUCCESS\"\n",
    "            else:\n",
    "                # If the conformer wasn't previously RUNNING, initialize it as SUCCESS\n",
    "                ts_conformers[ts][conformer_num] = {\n",
    "                    \"Conformer\": f\"Conformer {conformer_num}\",\n",
    "                    \"Status\": \"SUCCESS\",\n",
    "                    \"Methods\": \"\"\n",
    "                }\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return ts_conformers\n",
    "\n",
    "def write_conformers_to_csv(ts_conformers, csv_file_path):\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['TS', 'Conformer', 'Status', 'Methods']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for ts, conformers in ts_conformers.items():\n",
    "            for conformer_num, details in sorted(conformers.items()):\n",
    "                writer.writerow({\n",
    "                    'TS': ts,\n",
    "                    'Conformer': details[\"Conformer\"],\n",
    "                    'Status': details[\"Status\"],\n",
    "                    'Methods': ', '.join(details[\"Methods\"]) if details[\"Methods\"] else \"\"\n",
    "                })\n",
    "\n",
    "def main():\n",
    "    log_file_path = \"/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_746/arc.log\"\n",
    "    conformers_csv = 'conformers.csv'\n",
    "\n",
    "    ts_conformers = parse_arc_log(log_file_path)\n",
    "    \n",
    "    write_conformers_to_csv(ts_conformers, conformers_csv)\n",
    "\n",
    "    print(f\"Conformers data written to {conformers_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'TS0': {0: {'Conformer': 'Conformer 0',\n",
       "               'Status': 'SUCCESS',\n",
       "               'Methods': ''},\n",
       "              1: {'Conformer': 'Conformer 1',\n",
       "               'Status': 'RUNNING',\n",
       "               'Methods': ''},\n",
       "              2: {'Conformer': 'Conformer 2',\n",
       "               'Status': 'RUNNING',\n",
       "               'Methods': ''},\n",
       "              3: {'Conformer': 'Conformer 3',\n",
       "               'Status': 'SUCCESS',\n",
       "               'Methods': ''},\n",
       "              4: {'Conformer': 'Conformer 4',\n",
       "               'Status': 'FAILED',\n",
       "               'Methods': ['cartesian',\n",
       "                'int=(Acc2E=14)',\n",
       "                'NoSymm',\n",
       "                'opt=(maxcycle=200)',\n",
       "                'all_attempted']}}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file_path = \"/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_745/arc.log\"\n",
    "\n",
    "ts_conformers = parse_arc_log(log_file_path)\n",
    "ts_conformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'TS0': {0: {'Conformer': 'Conformer 0',\n",
       "               'Status': 'SUCCESS',\n",
       "               'Methods': ''},\n",
       "              1: {'Conformer': 'Conformer 1',\n",
       "               'Status': 'RUNNING',\n",
       "               'Methods': ''},\n",
       "              2: {'Conformer': 'Conformer 2',\n",
       "               'Status': 'RUNNING',\n",
       "               'Methods': ''},\n",
       "              3: {'Conformer': 'Conformer 3',\n",
       "               'Status': 'SUCCESS',\n",
       "               'Methods': ''},\n",
       "              4: {'Conformer': 'Conformer 4',\n",
       "               'Status': 'FAILED',\n",
       "               'Methods': ['cartesian',\n",
       "                'int=(Acc2E=14)',\n",
       "                'NoSymm',\n",
       "                'opt=(maxcycle=200)',\n",
       "                'all_attempted']}}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_conformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the ARC log file for Optimsation jobs of TS0\n",
    "\n",
    "# Read in ts_conformers from the previous step, a defaultdict of TSs with conformers\n",
    "\n",
    "successful_conformers = [conformer for conformer, details in ts_conformers[\"TS0\"].items() if details[\"Status\"] == \"SUCCESS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successful_conformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0']\n",
      "opt_a85721\n",
      "['0', '3']\n",
      "opt_a85744\n"
     ]
    }
   ],
   "source": [
    "# read in the arc.log file\n",
    "\n",
    "\n",
    "\n",
    "ts_optimizations = {\"TS0\": {}}\n",
    "#log_file_path = \"/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_746/arc.log\"\n",
    "log_file_path = \"/home/calvin/Dropbox/PersonalFolders/Calvin/ATLAS_Converged/rmg_rxn_745/arc.log\"\n",
    "\n",
    "with open(log_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "successful_conformers_copy = successful_conformers.copy()\n",
    "# Check for TS guess  [digits from successful_conformers] for TS0, and if found remove from successful_conformers_copy. if items still in list by the end, value error\n",
    "\n",
    "successful_conformer_pattern = re.compile(\n",
    "    r\"TS guess\\s+(\\d+) for (TS\\d+)\\.\"\n",
    ")\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i].strip()\n",
    "    successful_conformer_match = successful_conformer_pattern.match(line)\n",
    "    if successful_conformer_match:\n",
    "        conformer_num, ts = successful_conformer_match.groups()\n",
    "        conformer_num = int(conformer_num)\n",
    "        if ts == \"TS0\" and conformer_num in successful_conformers_copy:\n",
    "            successful_conformers_copy.remove(conformer_num)\n",
    "    i += 1\n",
    "    \n",
    "if successful_conformers_copy:\n",
    "    raise ValueError(f\"Failed to find successful conformers for TS0: {successful_conformers_copy}\")\n",
    "\n",
    "# Get max value from sucessful conformers and find TS guess  [MAX VALUE] for TS0 and then search the next lines for 'Optimizing species TS0' and then at the end of the line see which 'conformer [d+]' it is\n",
    "\n",
    "max_conformer = max(successful_conformers)\n",
    "\n",
    "# Find the pattern \"Optimizing species TS0\"\n",
    "\n",
    "optimization_run_pattern = re.compile(\n",
    "    r\"Running local queue job (opt_\\w+) using gaussian for (TS\\d+) \\(conformer (\\d+)\\)\"\n",
    ")\n",
    "\n",
    "job_number = []\n",
    "conformer_number = None\n",
    "for i, line in enumerate(lines):\n",
    "\n",
    "\n",
    "    if \"Optimizing species TS0\" in line:\n",
    "        # Get the conformer number/digit\n",
    "        line = line.strip()\n",
    "        conformer_number = re.findall(r'\\d+', line)\n",
    "        print(conformer_number)\n",
    "    if conformer_number:\n",
    "        # Go to next line, get the job number, for example Running local queue job opt_a85626 using gaussian for TS0 (conformer 2)\n",
    "        job_number_pattern = re.compile(\n",
    "            r\"Running local queue job (opt_\\w+) using gaussian for (TS\\d+) \\(conformer (\\d+)\\)\"\n",
    "        )\n",
    "        # Make sure the conformer number is the same as the one found in the previous line\n",
    "        try:\n",
    "            job_number_match = job_number_pattern.match(lines[i+1].strip())\n",
    "        except IndexError:\n",
    "            print(lines[i])\n",
    "        if job_number_match:\n",
    "            job_number = job_number_match.groups()\n",
    "            if job_number[2] == conformer_number[1]:\n",
    "                print(job_number[0])\n",
    "                \n",
    "                # Now record the job number and conformer number in a dictionary\n",
    "                if conformer_number[1] not in ts_optimizations[\"TS0\"]:\n",
    "                    if job_number[0] not in ts_optimizations[\"TS0\"]:\n",
    "                        ts_optimizations[\"TS0\"][conformer_number[1]] = {\n",
    "                            \"job\": [job_number[0]]\n",
    "                        }\n",
    "                    else:\n",
    "                        ts_optimizations[\"TS0\"][conformer_number[1]][\"job\"].append(job_number[0])\n",
    "    \n",
    "    # Need to see if it troubleshooted the current conformer, and if so, record the methods used and job number\n",
    "    if job_number and conformer_number:\n",
    "        if job_number[0] in line and 'Warning: Troubleshooting' in line:\n",
    "            print(line)\n",
    "            # Now need to find the next job it runs\n",
    "            for j in range(i+1, len(lines)):\n",
    "                if 'Running local queue job' in lines[j] and f\"conformer {conformer_number[1]}\" in lines[j]:\n",
    "                    job_number = job_number_pattern.match(lines[j].strip()).groups()\n",
    "                    # Access dict and add the job number \n",
    "                    ts_optimizations[\"TS0\"][conformer_number[1]][\"job\"].append(job_number[0])\n",
    "                    break\n",
    "                elif 'Troubleshooting opt job in gaussian' in lines[j] and 'was not successful' in lines[j] and 'Will not troubleshoot again':\n",
    "                    # Grab the next line to see the methods used - collect everyithing after 'with the following methods:'\n",
    "                    line_methods = lines[j+1].strip()\n",
    "                    methods_attempted_pattern = re.compile(\n",
    "    r\"Error: Could not troubleshoot geometry optimization for (TS\\d+)! Tried troubleshooting with the following methods: \\[(.*?)\\]\"\n",
    ")\n",
    "                    methods = methods_attempted_pattern.match(line_methods).groups()\n",
    "                    # Drop 'TS0' from the methods\n",
    "                    methods = methods[1].split(', ')\n",
    "                    # Access dict and add the methods\n",
    "                    ts_optimizations[\"TS0\"][conformer_number[1]][\"status\"] = 'Failed'\n",
    "                    ts_optimizations[\"TS0\"][conformer_number[1]][\"methods\"] = methods\n",
    "            \n",
    "                \n",
    "                \n",
    "        elif \"Running local queue\" in line and  f\"conformer {conformer_number[1]}\" in line and '(fine opt)' in line:\n",
    "            # Get the job_number\n",
    "            opt_pattern = re.compile(\n",
    "                r\"Running local queue job (\\w+) using gaussian for (TS\\d+) .*?\\(conformer (\\d+)\\)\"\n",
    "                )\n",
    "            job_opt_number = opt_pattern.match(line.strip()).groups()\n",
    "            # Access dict and add the opt job number\n",
    "            ts_optimizations[\"TS0\"][conformer_number[1]][\"opt_job\"] = job_opt_number[0]\n",
    "            \n",
    "            # See if it was successful\n",
    "            \n",
    "            for y in range(i+1, len(lines)):\n",
    "                if 'Ending job' in lines[y] and job_opt_number[0] in lines[y]:\n",
    "                    if 'Optimized geometry for TS0' in lines[y+2]:\n",
    "                        ts_optimizations[\"TS0\"][conformer_number[1]][\"opt_status\"] = 'Success'\n",
    "                        break\n",
    "        \n",
    "        if 'opt_status' in ts_optimizations[\"TS0\"][conformer_number[1]]:\n",
    "            if ts_optimizations[\"TS0\"][conformer_number[1]][\"opt_status\"] == 'Success':\n",
    "                freq_pattern = re.compile(\n",
    "                    r\"Running local queue job (\\w+) using gaussian for (TS\\d+)\"\n",
    "                )\n",
    "                \n",
    "                for z in range(i+1, len(lines)):\n",
    "                    if 'Running local queue job freq_' in lines[z]:\n",
    "                        freq_job_number = freq_pattern.match(lines[z].strip()).groups()\n",
    "                        # Access dict and add the freq job number\n",
    "                        ts_optimizations[\"TS0\"][conformer_number[1]][\"freq_job\"] = freq_job_number[0]\n",
    "                        \n",
    "                        # Need to find when it ends\n",
    "                        for w in range(z+1, len(lines)):\n",
    "                            if 'Ending job' in lines[w] and freq_job_number[0] in lines[w]:\n",
    "                                # Check 1 line after to see if has 'TS TS0 has exactly one imaginary frequency'\n",
    "                                if 'TS TS0 has exactly one imaginary frequency' in lines[w+1]:\n",
    "                                    # Capture the frequency after the ':' and add to dict\n",
    "                                    freq = lines[w+1].split(':')[-1].strip()\n",
    "                                    ts_optimizations[\"TS0\"][conformer_number[1]][\"freq\"] = freq\n",
    "                                    # Reset conformer_number\n",
    "                                    conformer_number = None\n",
    "                                    break\n",
    "                        break\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TS0': {'0': {'job': ['opt_a85721'],\n",
       "   'opt_job': 'opt_a85729',\n",
       "   'opt_status': 'Success',\n",
       "   'freq_job': 'freq_a85739',\n",
       "   'freq': '-335.2912'},\n",
       "  '3': {'job': ['opt_a85744'],\n",
       "   'opt_job': 'opt_a85750',\n",
       "   'opt_status': 'Success',\n",
       "   'freq_job': 'freq_a85780',\n",
       "   'freq': '-126.0315'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hab_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
